{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C8BS8OWsLEm"
      },
      "source": [
        "\n",
        "[Github project link text](https://github.com/camygiuliani/giuliani-tesinaLabIA2023.git)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8ns8oISp_vu"
      },
      "source": [
        "## Iniziamo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSqAxIkiLbM9"
      },
      "source": [
        "Questo è il mio progetto che ha come protagonista la Semantic Segmentation e la change detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rs_ubBrLh1Z"
      },
      "source": [
        "##Che cosa vogliamo fare?\n",
        "Si tratta di un problema di classificazione.Abbiamo a disposizione il dataset Sentinel2 con immagini satellitari , il nostro scopo sarà quello di classificare ogni pixel in base a 7 classi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-iLmrtcYk9Q"
      },
      "source": [
        "Importiamo le librerie e i moduli necessari."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weDSOihHXtpY",
        "outputId": "dc3242b6-cf82-4273-baaf-9a4b3b74286e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.7.0.72)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.6.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (8.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (23.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
            "Collecting segmentation_models_pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.15.2+cu118)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.2 (from segmentation_models_pytorch)\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.65.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (8.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.0.1+cu118)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0)\n",
            "Collecting huggingface-hub (from timm==0.9.2->segmentation_models_pytorch)\n",
            "  Downloading huggingface_hub-0.16.3-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm==0.9.2->segmentation_models_pytorch)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (23.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=9477c3a69db8296142c2a5e523a63bbf4575fa84ce4186a130384b3be73b4177\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=38723506352fa7c0b3dcf224e791dd1f62e7617391ec20ad6a792c072477f594\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: safetensors, munch, huggingface-hub, timm, pretrainedmodels, efficientnet-pytorch, segmentation_models_pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 huggingface-hub-0.16.3 munch-4.0.0 pretrainedmodels-0.7.4 safetensors-0.3.1 segmentation_models_pytorch-0.3.3 timm-0.9.2\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (1.3.8)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.5.7)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.3)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.22.4)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.0)\n",
            "Device cuda\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler, ConcatDataset\n",
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "!pip install albumentations\n",
        "import albumentations as A\n",
        "!pip install  segmentation_models_pytorch\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "\n",
        "!pip install rasterio\n",
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "\n",
        "torch.manual_seed(42) # Setting the seed\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "## colleghiamo con google dirve\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCi4CNcOJ8r0",
        "outputId": "5cf57e69-bcca-4168-e382-db0346f86fa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L'immagine ha dimensioni... (12, 1024, 1024)\n"
          ]
        }
      ],
      "source": [
        "##Osserviamo una specifica immagine\n",
        "file= rasterio.open(\"/content/drive/MyDrive/Lab_IA/sentinel2/1330_3107_13/2018_02.tif\").read()\n",
        "print(\"L'immagine ha dimensioni...\",file.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_leiGmH9QuoP"
      },
      "outputs": [],
      "source": [
        "## TUTTE LE COSTANTI QUA SOTTO\n",
        "EPOCHS= 200\n",
        "ROOT='/content/drive/MyDrive/Lab_IA'\n",
        "CLASS_LABELS={ 0: \"impervious serface\",\n",
        "               1: \"agriculture\",\n",
        "               2: \"forest & other vegetation\",\n",
        "               3: \"wetlands\",\n",
        "               4: \"soil\",\n",
        "               5: \"water\",\n",
        "               6:\"snow & ice\"}\n",
        "CHECKPOINT_DIR='/content/drive/MyDrive/Lab_IA/checkpoints'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjyJYoNiFXTs"
      },
      "source": [
        "Implementiamo la classe per il nostro dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duEFtITI4FSC"
      },
      "source": [
        "Come metriche utilizziamo\n",
        "\n",
        ">IoU: The ratio between the intersection and the union of the predicted\n",
        "segmentation and the ground truth.E'anche famosa come Jaccard Index,la usiamo per valutare l'accuratezza della sovrapposizione tra maschere predette e maschere di groud-truth\n",
        "\n",
        "\n",
        "> mIoU: The mean of the IoU values across all the classes\n",
        "\n",
        "![Screenshot from 2023-07-07 12-30-21.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UekbtAf7WpU"
      },
      "outputs": [],
      "source": [
        "## Funzioni per data augmentation\n",
        "def get_train_augmentations(image,mask):\n",
        "      '''\n",
        "      '''\n",
        "      transforms=[]\n",
        "      transforms.extend([\n",
        "          A.HorizontalFlip(p=0.5),\n",
        "          A.VerticalFlip(p=0.5),\n",
        "          A.RandomRotate90(p=1.0),\n",
        "      ])\n",
        "\n",
        "      return A.compose(transforms)\n",
        "\n",
        "def get_test_augmentations(image,mask):\n",
        "      transforms=[]\n",
        "\n",
        "      '''\n",
        "      '''\n",
        "\n",
        "      return A.compose(transforms)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w4BCNtbh7ccR"
      },
      "outputs": [],
      "source": [
        "## funzioni per metriche\n",
        "\n",
        "def get_intersection_union(pred,label,n_classi):\n",
        "    #pred è un tensore(altezza,profondità)\n",
        "    #convertiamo in np.array\n",
        "    ## aggiungiamo +1 per ignorare i valori -1 corrispondenti alla classe snow and ice\n",
        "    pred=np.asarray(pred)+1\n",
        "    label= np.asarray(label)+1\n",
        "\n",
        "    #elimino tutti gli elementi in pred corrispondenti alla classe 0\n",
        "    pred= pred * (label>0)\n",
        "    # calcolo intersezione\n",
        "    intersezione= (pred==label)*pred\n",
        "    inters_area= np.histogram(intersezione,bins=n_classi,range=(1,n_classi))\n",
        "    pred_area= np.histogram(pred,bins=n_classi,range=(1,n_classi))\n",
        "    label_area= np.histogram(label,bins=n_classi,range=(2,n_classi))\n",
        "\n",
        "    ## per il calcolo dell'area di unione sommo le aree di pred e label e sottraggo l'intersezione\n",
        "    unione_area= pred_area+label_area-inters_area\n",
        "    return inters_area,unione_area\n",
        "\n",
        "def get_IoU(intersezione,unione):\n",
        "  iou= intersezione/unione\n",
        "  return iou\n",
        "\n",
        "def get_mIoU(iou_values):\n",
        "  mean_iou= np.mean(iou_values)\n",
        "  return mean_iou\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "bFGTJQMZFWjz",
        "outputId": "9cbf0b1d-0dca-43d2-8fab-0ef241ec87dd"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-92c113b329f2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMyDynamicEarthNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \"\"\"\n\u001b[1;32m      4\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mroot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mplanet\u001b[0m \u001b[0mimagery\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ],
      "source": [
        "class MyDynamicEarthNet(Dataset):\n",
        "    def __init__(self, root, mode, mean=np.zeros((12,)),std=np.zeros((12,)),num_classes=7 ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root: the root of the folder which contains planet imagery and labels\n",
        "            mode: train/val/test -- selects the splits\n",
        "\n",
        "            reference_date: for positional encoding defaults:2018-01-01\n",
        "            crop_size: crop size default:1024x1024\n",
        "            num_classes: for DynamicEarthNet numclasses: 6\n",
        "\n",
        "        \"\"\"\n",
        "        self.root = root\n",
        "        self.mode = mode\n",
        "        self.resize = crop_size\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.mean=mean\n",
        "        self.std=std\n",
        "        self.normalize = transforms.Normalize(mean=self.mean, std=self.std)\n",
        "\n",
        "        self.files,self.labels= self.get_file_labels(mode)\n",
        "\n",
        "        if(mode==\"train\"):\n",
        "          self.augmentations= self.get_train_augmentations()\n",
        "        else:\n",
        "          self.augmentations= self.get_test_augmentations()\n",
        "\n",
        "        self.calculate_mean_std()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def get_file_labels(self,mode):\n",
        "\n",
        "      with open(os.path.join(self.root,self.mode+\".txt\"),\"r\") as f:\n",
        "        lista_file=[]\n",
        "        for line in f:\n",
        "          line=line.rstrip().split(' ')\n",
        "          lista_file.append(line)\n",
        "        self.files,self_labels=list(zip(*lista_file))\n",
        "\n",
        "      self.mean,self.std= self.calculate_mean_std()\n",
        "\n",
        "      return self.files, self_labels\n",
        "\n",
        "\n",
        "    def set_files(self):\n",
        "        self.file_list = os.path.join(self.root, \"dynnet_training_splits\", f\"{self.mode}\" + \".txt\")\n",
        "        print (self.file_list)\n",
        "        file_list = [line.rstrip().split(' ') for line in tuple(open(self.file_list, \"r\"))]\n",
        "        self.files, self.labels, self.year_months = list(zip(*file_list))\n",
        "\n",
        "        if self.type == 'daily':\n",
        "            self.all_days = list(range(len(self.files)))\n",
        "\n",
        "            for i in range(len(self.files)):\n",
        "                self.planet, self.day = [], []\n",
        "                date_count = 0\n",
        "                for _, _, infiles in os.walk(os.path.join(self.root, self.files[i][1:])):\n",
        "                    for infile in sorted(infiles):\n",
        "                        if infile.startswith(self.year_months[i]):\n",
        "                            self.planet.append(os.path.join(self.files[i], infile))\n",
        "                            self.day.append((datetime(int(str(infile.split('.')[0])[:4]), int(str(infile.split('.')[0][5:7])),\n",
        "                                                  int(str(infile.split('.')[0])[8:])) - self.reference_date).days)\n",
        "                            date_count += 1\n",
        "                self.all_days[i] = list(zip(self.planet, self.day))\n",
        "                self.all_days[i].insert(0, date_count)\n",
        "\n",
        "        else:\n",
        "            self.planet, self.day = [], []\n",
        "            if self.type == 'weekly':\n",
        "                self.dates = ['01', '05', '10', '15', '20', '25']\n",
        "            elif self.type == 'single':\n",
        "                self.dates = ['01']\n",
        "\n",
        "            for i, year_month in enumerate(self.year_months):\n",
        "                for date in self.dates:\n",
        "                    curr_date = year_month + '-' + date\n",
        "                    self.planet.append(os.path.join(self.files[i], curr_date + '.tif'))\n",
        "                    self.day.append((datetime(int(str(curr_date)[:4]), int(str(curr_date[5:7])),\n",
        "                                                  int(str(curr_date)[8:])) - self.reference_date).days)\n",
        "            self.planet_day = list(zip(*[iter(self.planet)] * len(self.dates), *[iter(self.day)] * len(self.dates)))\n",
        "\n",
        "\n",
        "    def load_data(self, index):\n",
        "        cur_images, cur_dates = [], []\n",
        "        if self.type == 'daily':\n",
        "            for i in range(1, self.all_days[index][0]+1):\n",
        "                img = rasterio.open(os.path.join(self.root, self.all_days[index][i][0][1:]))\n",
        "                red = img.read(3)\n",
        "                green = img.read(2)\n",
        "                blue = img.read(1)\n",
        "                nir = img.read(4)\n",
        "                image = np.dstack((red, green, blue, nir))\n",
        "                cur_images.append(np.expand_dims(np.asarray(image, dtype=np.float32), axis=0)) # np.array already\\\n",
        "                cur_dates.append(self.all_days[index][i][1])\n",
        "\n",
        "            image_stack = np.concatenate(cur_images, axis=0)\n",
        "            dates = torch.from_numpy(np.array(cur_dates, dtype=np.int32))\n",
        "            label = rasterio.open(os.path.join(self.root, self.labels[index][1:]))\n",
        "            label = label.read()\n",
        "            mask = np.zeros((label.shape[1], label.shape[2]), dtype=np.int32)\n",
        "\n",
        "            for i in range(self.num_classes + 1):\n",
        "                if i == 6:\n",
        "                    mask[label[i, :, :] == 255] = -1\n",
        "                else:\n",
        "                    mask[label[i, :, :] == 255] = i\n",
        "\n",
        "            return (image_stack, dates), mask\n",
        "\n",
        "        else:\n",
        "            for i in range(len(self.dates)):\n",
        "                # read .tif\n",
        "                img = rasterio.open(os.path.join(self.root, self.planet_day[index][i][1:]))\n",
        "                red = img.read(3)\n",
        "                green = img.read(2)\n",
        "                blue = img.read(1)\n",
        "                nir = img.read(4)\n",
        "                image = np.dstack((red, green, blue, nir))\n",
        "                cur_images.append(np.expand_dims(np.asarray(image, dtype=np.float32), axis=0))   # np.array already\\\n",
        "            image_stack = np.concatenate(cur_images, axis=0)\n",
        "            dates = torch.from_numpy(np.array(self.planet_day[index][len(self.dates):], dtype=np.int32))\n",
        "            label = rasterio.open(os.path.join(self.root, self.labels[index][1:]))\n",
        "            label = label.read()\n",
        "            mask = np.zeros((label.shape[1], label.shape[2]), dtype=np.int32)\n",
        "\n",
        "            for i in range(self.num_classes+1):\n",
        "                if i == 6:\n",
        "                    mask[label[i, :, :] == 255] = -1\n",
        "                else:\n",
        "                    mask[label[i, :, :] == 255] = i\n",
        "\n",
        "            return (image_stack, dates), mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ##immagine cercata\n",
        "        imm= rasterio.open(os.path.join(self.root,self.files[index])).read()\n",
        "\n",
        "        ##il formato giusto è float32\n",
        "        imm=imm.astype(np.float32)\n",
        "\n",
        "        ##carico anche l'etichetta\n",
        "        label= rasterio.open(os.path.join(self.root,self.labels[index])).read()\n",
        "        ##maschera per la classe\n",
        "        mask=np.zeros((label.shape[1],label.shape[2]),dtype=np.int64)     ## label.shape[1] la larghezza e label.shape [2] per altezza\n",
        "        for i in range(self.num_classi):\n",
        "          ## non considero la classe 6 corrispondente a snow and ice\n",
        "          if i==6:\n",
        "            mask[label[i,:,:]==255]=-1\n",
        "          else:\n",
        "            mask[label[i,:,:]==255]=i\n",
        "\n",
        "        ## è il momento di normalizzare e fare data augmentation\n",
        "        imm_trasp=imm.transpose(1,2,0)\n",
        "        augm= self.augmentations(image=imm_trasp,mask=mask)\n",
        "        ##applico augmentation\n",
        "        augm_img= augm[\"image\"]\n",
        "        ##transformo in tensore\n",
        "        img= torch.from_numpy(augm_img.transpose(2,0,1))\n",
        "\n",
        "        '''\n",
        "        '''\n",
        "        #normalizzo\n",
        "        img=self.normalize(img)\n",
        "\n",
        "\n",
        "        return img, mask\n",
        "\n",
        "\n",
        "\n",
        "    def calculate_mean_std(self):\n",
        "      # Mean\n",
        "      print(\"Sto calcolando la media\")\n",
        "      sum= np.zeros((12,))\n",
        "      num_pixel=0\n",
        "      for im in tqdm(self.files):\n",
        "        im_path= os.path.join(self.root,im)\n",
        "        src= rasterio.open(im_path)\n",
        "        img=src.read()\n",
        "        sum += np.sum(img,axis={1,2})\n",
        "        num_pixel+=img.shape[1]* img.shape[2]\n",
        "\n",
        "      mean= sum/num_pixel\n",
        "\n",
        "      ## Deviazione standard\n",
        "      sum= np.zeros((12,))\n",
        "      for im in tqdm(self.files):\n",
        "        im_path= os.path.join(self.root,im)\n",
        "        src= rasterio.open(im_path)\n",
        "        img=src.read()\n",
        "        sum += np.sum((img-mean.reshape(12,1,1))**2,axis={1,2})\n",
        "\n",
        "      std= np.sqrt(sum/num_pixel)\n",
        "\n",
        "      self.mean=mean\n",
        "      self.std=std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-1pwISFJuOp"
      },
      "outputs": [],
      "source": [
        "##creazione training, validation e test set\n",
        "training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxb_49oKI7xS"
      },
      "source": [
        "Parte sui DataLoader che non so assolutamente come fare :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4CE6ti1I51I"
      },
      "outputs": [],
      "source": [
        "# Crea il DataLoader utilizzando il dataset\n",
        "dataloader = DataLoader(training, batch_size=??, shuffle=True, num_workers=yes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwwvdos0G1AY"
      },
      "source": [
        "#UNet\n",
        "Implementiamo adesso la rete UNet che è una fully-convolutional-network\n",
        "\n",
        "First path is the contraction path (also called as the encoder) which is used to capture the context in the image. The encoder is just a traditional stack of convolutional and max pooling layers. The second path is the symmetric expanding path (also called as the decoder) which is used to enable precise localization using transposed convolutions. Thus it is an end-to-end fully convolutional network (FCN), i.e. it only contains Convolutional layers and does not contain any Dense layer because of which it can accept image of any size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj6L0xkDH0xE",
        "outputId": "b2672a91-99cc-4b29-d05a-95a4615268e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 94.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet(\n",
            "  (model): Unet(\n",
            "    (encoder): ResNetEncoder(\n",
            "      (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (layer1): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (2): BasicBlock(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (layer2): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (2): BasicBlock(\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (3): BasicBlock(\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (layer3): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (2): BasicBlock(\n",
            "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (3): BasicBlock(\n",
            "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (4): BasicBlock(\n",
            "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (5): BasicBlock(\n",
            "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (layer4): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (2): BasicBlock(\n",
            "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (decoder): UnetDecoder(\n",
            "      (center): Identity()\n",
            "      (blocks): ModuleList(\n",
            "        (0): DecoderBlock(\n",
            "          (conv1): Conv2dReLU(\n",
            "            (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (attention1): Attention(\n",
            "            (attention): Identity()\n",
            "          )\n",
            "          (conv2): Conv2dReLU(\n",
            "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (attention2): Attention(\n",
            "            (attention): Identity()\n",
            "          )\n",
            "        )\n",
            "        (1): DecoderBlock(\n",
            "          (conv1): Conv2dReLU(\n",
            "            (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (attention1): Attention(\n",
            "            (attention): Identity()\n",
            "          )\n",
            "          (conv2): Conv2dReLU(\n",
            "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (attention2): Attention(\n",
            "            (attention): Identity()\n",
            "          )\n",
            "        )\n",
            "        (2): DecoderBlock(\n",
            "          (conv1): Conv2dReLU(\n",
            "            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (attention1): Attention(\n",
            "            (attention): Identity()\n",
            "          )\n",
            "          (conv2): Conv2dReLU(\n",
            "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (attention2): Attention(\n",
            "            (attention): Identity()\n",
            "          )\n",
            "        )\n",
            "        (3): DecoderBlock(\n",
            "          (conv1): Conv2dReLU(\n",
            "            (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (attention1): Attention(\n",
            "            (attention): Identity()\n",
            "          )\n",
            "          (conv2): Conv2dReLU(\n",
            "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (attention2): Attention(\n",
            "            (attention): Identity()\n",
            "          )\n",
            "        )\n",
            "        (4): DecoderBlock(\n",
            "          (conv1): Conv2dReLU(\n",
            "            (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (attention1): Attention(\n",
            "            (attention): Identity()\n",
            "          )\n",
            "          (conv2): Conv2dReLU(\n",
            "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (attention2): Attention(\n",
            "            (attention): Identity()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (segmentation_head): SegmentationHead(\n",
            "      (0): Conv2d(16, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Identity()\n",
            "      (2): Activation(\n",
            "        (activation): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "n_channels=12\n",
        "class UNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(UNet,self).__init__()\n",
        "    self.model = smp.Unet(in_channels=n_channels,classes=1,)\n",
        "    self.model.encoder.conv1=nn.Conv2d(n_channels,out_channels=32,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)\n",
        "    self.model.segmentation_head[0]=nn.Conv2d(16,6,kernel_size=(1,1),stride=(1,1))\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.model(x)\n",
        "\n",
        "##testing my unet\n",
        "model=UNet()\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUB8LVj-9cUP",
        "outputId": "2ab52f22-00a6-4f15-fe12-5070b4b26151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting segmentation_models_pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.15.2+cu118)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.2 (from segmentation_models_pytorch)\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.65.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (8.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.0.1+cu118)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0)\n",
            "Collecting huggingface-hub (from timm==0.9.2->segmentation_models_pytorch)\n",
            "  Downloading huggingface_hub-0.16.2-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.5/268.5 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm==0.9.2->segmentation_models_pytorch)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (23.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=f2dc1e6663a58f49c05eb525fb6901ae84a0874cd62b0ac1fa9b0bd085cda568\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=13078ca9d6419a8b767bf1923c8403226f4994780465e61feb620eec074885cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: safetensors, munch, huggingface-hub, timm, pretrainedmodels, efficientnet-pytorch, segmentation_models_pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 huggingface-hub-0.16.2 munch-4.0.0 pretrainedmodels-0.7.4 safetensors-0.3.1 segmentation_models_pytorch-0.3.3 timm-0.9.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 89.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unet(\n",
            "  (encoder): ResNetEncoder(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (5): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): UnetDecoder(\n",
            "    (center): Identity()\n",
            "    (blocks): ModuleList(\n",
            "      (0): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (1): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (2): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (3): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "      (4): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): Attention(\n",
            "          (attention): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (segmentation_head): SegmentationHead(\n",
            "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Identity()\n",
            "    (2): Activation(\n",
            "      (activation): Identity()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.models.segmentation as models\n",
        "!pip install segmentation_models_pytorch\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Carica il modello U-Net predefinito\n",
        "model = smp.Unet()\n",
        "\n",
        "# Stampa l'architettura del modello\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "clRcfgmQHD97"
      },
      "outputs": [],
      "source": [
        "###Per checkpoint\n",
        "\n",
        "\n",
        "# Loop di addestramento\n",
        "for epoch in range(num_epochs):\n",
        "    # Fai l'addestramento per l'epoca corrente\n",
        "    ...\n",
        "\n",
        "    # Salva il checkpoint dopo ogni epoca\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        # Aggiungi altre informazioni pertinenti al checkpoint\n",
        "        ...\n",
        "    }\n",
        "    torch.save(checkpoint, f'checkpoint_epoch_{epoch}.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVdxzzFxHKcz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
